## 传统召回
> 此类算法基于规则和统计，无需训练模型
> 优势：可解释性强，能针对性的更改，而模型是个黑盒，很难针对性的提升某指标

1. 基于物料的倒排索引
	1. 离线时，将具备相同属性的物料集合起来，每个集合内部按照后验消费指标降序排列
	2. 线上推荐时，提取用户喜欢标签，再据此检索倒排索引
2. 基于统计的协同过滤算法
	1. `UserCF`
	2. `ItemCF`
3. 矩阵分解：被淘汰的方法？？

如何合并多路召回？

## 向量召回
> 所谓向量召回，即将召回问题建模成向量空间的紧邻搜索问题

从形式上可划分为三类：
1. `I2I`：用于给用户找与他喜欢的物料相似的其他物料
2. `U2I`：用于给用户直接找他喜欢的物料
3. `U2U`：用于给用户查找与他相似的用户，再将相似用户喜欢物品推荐给当前用户

基本套路：
1. 训练模型，将实体`Q`和`T`中每个实例映射成向量
2. 离线缓存，将实体T中每个实例经模型推理的向量缓存到**向量数据库**中
3. 在线服务时，实体Q的一个实例经模型推理得到向量`Emb_q`，再在向量数据库中通过近邻搜索查找K个T类邻居向量

向量化召回包含大量的算法，但均有以下四个纬度构成：
1. 如何定义正样本
	1. `I2I`：同一个用户在同一个`session（间隔时间较短的用户行为序列）`中交互过的两个物料
	2. `U2I`：用户与其交互过的物料
	3. `U2U`：
2. 如何定义负样本：关键在于让模型见识到形形色色，五花八门的负样本
	1. 全部物料池随机采样（简单负样本）
	2. 困难负样本（与前者比例，1：100）：用于帮助召回模型关注一些细粒度的特征
3. 如何将Q和T映射为`Embedding`向量
	1. 必须解耦生成
4. 如何定义优化目标（损失函数）
	1. 
### Item2Vec
> 借鉴NLP中的`Word2Vec`算法，I2I召回

### Airbnb召回

1. Item2Vec中认为一个session用户交互序列中某物料前后出现的物料为彼此的正样本
	1. Airbnb改进：如果一个点击序列最终导致某个房屋（item）被成功预定，则额外增加一批正样本：点击序列中每个房屋与被成功预定的房屋
2. 负样本选择：Airbnb针对自身业务场景引入了Hard Negative Sample
3. Airbnb的U2I召回：
	1. 用户预定记录以及房屋被预定记录非常有限，不足以支撑模型学习高质量的embedding
	2. Airbnb根据属性和人工规则，将用户和房屋分类，单个用户与单个房屋的预定记录是稀疏的，但单类用户与单类房屋的预定记录就丰富许多
	3. 正样本选择：某一用户u预定过某房屋l，则u所属类别U和l所属类别L为正样本
	4. 负样本选择：
### EGES
> Enhanced Graph Embedding with Side Information

### FM

### 双塔模型

### GCN

## ANN算法
> 近似近邻搜索（Approximate Nearest Neighbors，ANN）

Annoy：

Faiss：Facebook开发