>1. [正式赛第一名](https://github.com/wj19971997/NEWS-RECOMMENDATION?spm=a2c22.21852664.0.0.3202658fJVqOUY)
>2. [正式赛第二名](https://github.com/LogicJake/tianchi-news-recommendation?spm=a2c22.21852664.0.0.5832f169YJjfw4)
>3. [正式赛第三名](https://github.com/ikaruga0508/tianchi_news_pub)

数据：
1. `train_click_log.csv`：训练集用户（20w用户）点击日志
2. `testA_click_log.csv`：测试集A用户（5w用户）点击日志（A榜）
3. `testB_click_log.csv`：测试集B用户（5w用户）点击日志（B榜）

训练集，测试集A，测试集B中的用户均不存在交叉。
训练集点击时间：`2017-10-03 11:18:52 2017-11-13 20:04:14`（六周）
1. 绝大多数用户的点击时间处于`2017-10-03 11:18:52 2017-10-25 07:56:58`（三周）
2. 仅有**14个用户**的点击时间处于`2017-10-25 07:56:58`之后
测试集A点击时间：`2017-10-02 15:44:10 2017-10-24 07:56:58`（三周）
测试集B点击时间：`2017-10-01 20:27:43 2017-10-23 15:25:23`（三周）

## A榜/B榜区别
Kaggle中有`public LB`和`private LB`，区别在于用户提交结果时，包含全量测试集的预测结果，但Kaggle仅会从测试集中选择一部分样本的预测结果来计算`public LB`，另一部分计算`private LB`（但只在结束比赛时公开）

此处的A榜与B榜则类似于上述操作，只是其一开始便将全量测试集拆分为A，B两部分，测试集A供日常调试使用，测试集B公开时间一般只有3-24小时的窗口期（视数据集规模而定），确保参赛者无法进行大规模的模型调整和优化。

训练集，序列长度：`2-241`
1. 序列长度为2占比：40.819%
测试集A，序列长度：`1-938`
1. 序列长度为1占比：19.04%
测试集B，序列长度：`1-500`
1. 序列长度为1占比：14.828%

本地CV构建：
1. 训练集用户中随机采样5w作为线下验证集用户，将验证集用户的最后一次点击记录从原训练集的点击日志中剔除（需保证线下验证集用户至少有两次点击记录）
	1. 根据构造的线下验证集可知：**12%的待预测新闻并未出现在历史点击日志中**
2. 合并训练集点击日志与测试集A点击日志作为总的历史点击记录，预测验证集用户的最后一次点击作为线下验证。

线上提交：
1. 使用全量训练集+测试集A进行训练。
	1. 双塔模型训练时，由于测试集A存在长度为1的序列，故也需要作冷启动召回

## Recall

### 多路召回

1. `I2I_CF`：基于`user-item`倒排表（item共现次数）构建相似度矩阵
	1. 除了考虑共现次数外，还考虑点击位置，顺序和逆序等因素
	2. 若某文章未出现在日志中，则无法获取该文章与其他文章的相似度（**无法对冷启动文章进行推荐**）
	3. 召回时，**不会采用用户全部历史点击新闻，而仅采用最近点击的topk个新闻做召回**
	4. CV Recall@50：0.58003
3. `U2I_Model`：基于日志信息训练出`user`和`item`的`embedding`向量，再通过最近邻寻找与user emb相近的item emb进行召回
	1. 仅能训练出出现在日志中文章的`embedding`向量
	2. 用户历史交互序列为1的用户模型无法捕获其特征，故无法进行推荐（**无法对冷启动用户进行推荐**）
	3. CV Recall@50：
4. `U2U_emb_CF`：
	1. 基于`item-user`倒排表构建相似度矩阵，内存要求极高，无法运行
	2. 基于双塔模型训练得到的`user_embedding`构建相似度矩阵并进行召回
5. 文章冷启动：基于题目给定的`article_embedding`构建相似度矩阵
	1. 首先基于相似度矩阵进行召回
		1. CV Recall@50：0.0262
	2. 基于规则进行筛选，例如：筛选出文章类型，文章字数，文章创建时间相近的文章作为最终召回结果
		1. CV Recall@50：0.00234
6. 用户冷启动：
	1. 
7. 多路合并：
	1. 每次挑选每一路分数最高的添加进最终召回列表，重复的去除，直至打到召回数量
	2. CV Recall@50：

## Rank

### 特征工程
> 构造特征，构造用于排序模型的监督数据集

现有特征：
1. 文章自身属性，例如：`category_id, created_at_ts, words_count`
2. 文章内容`embeding`
3. 用户自身属性，例如：`click_environment, click_os, ...`

**如何挖掘其他特征信息？**
	1. 挖掘用户候选item与其**历史点击文章的关联信息**：
		1. `embedding 内积`，其中有多种可用的`embedding`，例如：数据提供的基于内容的embedding，YoutubeDNN训练得到的item embedding，也可以根据历史序列，经w2v训练得到item embedding
		2. 统计特征（字数，建立时间差...）
	2. 用户画像
		1. 活跃度（综合点击次数，点击时间（点击频率）考虑）
		2. 设备习惯，时间习惯，主题爱好，字数偏好...
	3. 文章画像
		1. 主题，字数，创建时间，文章热门...

召回结果有两类，一类为`Embedding`信息，双塔模型为每个用户和物品都生成了一个`Embedding`向量（可用于构造特征），还有一类为每个用户有一个召回列表：
```python
{
 user_id_1:[(item_id_1,score_1),(item_id_2,score_2),...],
 user_id_2:[...]
}
```
如何构造用于排序模型训练的数据集呢？最终形似如下：
```python
[ user_id | item_id | feature_1 | feature_2 | ... | label ]
[    u1   |    i1   |     ?     |     ?     | ... |   ?   ]
[    u1   |    i2   |     ?     |     ?     | ... |   ?   ]
[    u2   |    i4   |     ?     |     ?     | ... |   ?   ]
[    u2   |    i5   |     ?     |     ?     | ... |   ?   ]
```
也即先将上述召回列表展开，再**向其中补充特征与标签**。

### 精排数据集

在构造标签时，获取训练集用户最后一次点击的文章id，其对应label为1，其余均为0。也即将召回未点击近似看作曝光未点击。这样的后果是正负样本极度不平衡，故需要对负样本进行下采样。

**疑问：为什么不像召回阶段一样，通过滑动窗口扩充数据集呢？也即扩充一些正样本呢？**
召回结果本身就是基于每个用户前n-1个交互文章对其下一个点击文章的预测，故无法再使用滑动窗口扩充数据集。

采样时需要注意：确保每个用户以及每个物品均在数据集出现至少一次，不能因为下采样导致其丢失。

### DIN Rank
较之`LightGBM`直接输入一个表格数据，排序阶段的`DIN`模型同召回阶段的`YoutubeDNN`模型一样，需要将数据集划分为`数值型特征，离散型特征以及历史行为序列特征`。

当然这个过程是在前面得到数据集的基础上进行的。
## Appendix

### Pandas
1. `pd.concat`：堆叠数据，不考虑数据之间键的关系，类比于SQL中的`union`
	1. 例如：`train_click_log`，`testA_click_log`
	2. 参数：`ignore_index`，一般设置为`True`，即忽略原先数据中的index，concat之后重新计数（否则concat之后的数据可能存在重复索引）
		1. **索引`Index`：可以视作`DataFrame`的横向索引，纵向索引是`Column`**
2. `pd.merge`：合并数据，根据数据之间的键值对合并，类比于SQL中的`join`
	1. 例如：`train_click_log`和`articles`
	2. 参数：`how`
		1. `inner`：保留两个df中键匹配的行，不匹配的均删去
		2. `left`：保留左侧所有行，如果右侧数据不存在与左侧匹配数据则置NaN
3. `DataFrame[Column]`：返回`Series`对象
	1. `DataFrame[Column].values`：返回**numpy数组**（数值计算更有优势）
	2. `DataFrame[Column].tolist()`：返回python的**list结构**（便于python操作）
4. `DataFrame[[Column]]`：返回仅含`Column`列的`DataFrame`对象
5. `DataFrame.iloc`：与`loc`功能一致，区别在于其使用整数作为索引，后者选择标签作为索引，与`DF[column]`的区别在于其即可选择行，又可选择列
	1. `DF.iloc[i]`：选择第i行
	2. `DF.iloc[:,i]`：选择第i列
6. `DataFrame.loc`
7. `DataFrame.apply(lambda x:f(x))`：默认x为`Series`，表示某一列的所有数据
8. `DataFrame.groupby("Column")`：
	1. 遍历：key为对应Column的值，value为`DataFrame`，包含所有属于key的行